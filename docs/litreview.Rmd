# Literature Review {#litreview}

Social networks have been studied for decades, beginning with a few foundational works, the most well known of which is the 1967 study, "The Small World Problem" by Stanley Milgram [@goldenberg09]. But in recent years, the study of social networks has grown wildly in popularity due to an increase in the availability of and easy of access to social network data. The digital revolution has led to the creation of social media, linking people from all over the world in a way we never have been before. Now that platforms like Facebook, Twitter, and LinkedIn permeate our world, just about everyone knows what social networks are. In academic circles, collaboration networks are a type of social network that have been extensively studied and can even be a point of pride, like a mathematician's Erd&#x00F6;s  number [@erdos]. Social networks are a rich source of knowledge, but the data format does not fit easily within traditional data collection paradigms. Traditionally, data collection involves a set of units of the same, or at least similar, kind, on which observations are made. The storage of traditional data is simple and organized: rows contain variable values collected from units. These units can be people, plants, animals, stocks, objects, fields, and anything else under the sun, but one social network consits of many units, yet on the whole is just one observation. When observing a social network, one observes the possibly very numerous actors (also referred to as vertices or nodes) and the relationships (also referred to as edges or ties) between those actors. One can also collect information on the nodes and the edges separately, such as the age or gender of people and the length of their relationship or how strong it is in a friendship network. Thus, information on the entire network is more difficult to store than traditional data with which statisticians usually work. 

This apparent difficulty has not stopped researchers in many different fields from studying social and other types of networks. Sociologists work with human relationship networks of all kinds imaginable, biologists work with protein-protein interaction networks, neurologists use fMRI scans to study biologic neural networks, and the list goes on. These disciplines worked separately for many years, each developing their own measures, softwares, and theories about the fundamental properties of networks. And although statisticians were comparatively late to the party, many statistical models exist for network analysis. Beginning with the classic Erd&#x00F6;s-R&#x00E9;nyi random graph model and varying in structure, complexity, and application to include longitudinal network data, such as continuous time markov chain models [@goldenberg09]. The many varying models that exist just for social network analysis are impressive, but I focus my research on one type of continuous time markov chain (CTMC) models, called Stochastic Actor-Oriented Models (SAOMs). A full introduction to the various models that exist for social network analysis is presented in Section \@ref(models), and a full introduction to the structure and theory of SAOMs is presented in Section \@ref(saoms). 

## Statistical Models for Social Networks {#models}

The literature on statistical models for networks is extensive. In their thorough "Survey of Statistical Models", Goldenberg et al separate these models in to two primary classes: static and dynamic. I discuss the several types of models in each of these two categories after a brief introductory section on general network terminology and notation. 

### Basic Network Terminology and Notation {#netterm}

Formally, a network is a collection of nodes and the set of ties between them. Nodes are also referred to as vertices primarily in the graph theory literature or actors in the sociology literature, while ties are also called edges or relationships. In graph theory, a network is defined with respect to its nodes and edges, and a network $G$ is equivalently written as $G(\mathcal{N}, \mathcal{E})$, where $\mathcal{N}$ is the collection of nodes, or nodeset, and $\mathcal{E}$ is the collection of edges, or edgeset. Typically, the nodes are numbered so that $\mathcal{N} = {1, 2, \dots, n}$, where $n$ is the total number of nodes in the network. The edgeset $\mathcal{E}$ is usually described as a set of pairs, written as $(i,j)$ or $i \mapsto j$ or simply $ij$, where $i \neq j \in \mathcal{N}$. In an undirected network, the ordering of $i$ and $j$ does not matter: there is no parent-child relationship, to use a term from graph theory, just a connection of some kind. In a directed graph, however, the order does matter: the tie $(i,j)$ is not equivalent to the tie $(j,i)$. In an undirected graph, the number of possible edges is $\binom{n}{2}$, while in directed graphs it is $n(n-1)$, assuming no self-loops (also called self-ties or simply loops) and only allowing for at most one edge between any two nodes. 

In statistical network analysis, a network is denoted by $x$ if it is observed or by $X$ if it is being treated as unobserved or as a random variable. Following this convention, edges in the networks $x$ or $X$ are denoted by $x_{ij}$ or $X_{ij}$, respectively. If the edge $i \mapsto j$ is present, $x_{ij} = 1$, whereas $x_{ij} = 0$ if the edge is not present. If $x$ is undirected, then $x_{ij} = x_{ji} \forall i \neq j \in \mathcal{N}$. If $x$ is directed, then $x_{ij}$ may equal $x_{ji}$, but this is not required and should not be assumed. Note that the definition of binary edge variables makes the assumption that edges are unweighted and that their cannot be more than one edge between two nodes. There are graphs and networks with weighted edges or with multiple ties between nodes, such as correlation networks used for modelling fMRI data or network-based epidemic modeling with finite, discrete state spaces [@Kolaczyk2009]. The models I discuss here, including the stochastic actor-oriented models that are my primary focus, are all for unweighted networks, though some allow for extension to weighted networks. 

A network $x$ can also be expressed as an $n \times n$ matrix of 0s and 1s called the adjacency matrix, denoted $\mathcal{A}(x)$. The $ij^{th}$ entry of this matrix, $a_{ij}$ is 1 if there is an edge between nodes $i$ and $j$ and 0 otherwise. Typically, in statstical network analysis, the diagonal entries of this matrix, $a_{ii}$ are structurally 0, as self-ties or self-loops are not allowed or do not make sense. 

### Static Network Models {#staticnets}

The Erd&#x00F6;s-R&#x00E9;nyi random graph model is widely regarded as the first random graph model [@goldenberg09]. In this model, first introduced in @er59, a random, undirected graph or network, $G$, is described in terms of its nodeset, $N$, and its edgeset, $E$, where $E$ is a random subset of the $\binom{|N|}{2}$ possible edges in the nodeset. The parameter in this model is $p$, the probability of an edge between any two nodes in $N$. The likelihood is written in terms of $|E|$ and $p$, 
$$f_G(|E| | p, N) = p^{|E|}(1-p)^{\binom{|N|}{2} - |E|}.$$
The properties and asymptotic behavior of this network model are well-established [@goldenberg09]. Nodes in networks generated using this model will all have about the same degree, or number of incident edges, which is a very unrealistic property for networks to have. As such, many other models have been devised over the years as a way to better capture the the network creation process underlying real-world networks. 

A set of models which has also been very extensively studied is the exponential random graph family of models (ERGMs). The first, less general form of these models is the $p_1$ model for social networks, first introduced in @p1model. The $p_1$ model was developed for modelling directed networks, also called directed graphs or digraphs. In this model, the edges state, $(x_{ij}, x_{ji})$ between a pair of nodes, $(i, j)$ for all $i \neq j \in N$, could exist in one of four possible states: $(0,0)$ (no ties between $i,j$), $(1,0)$ (a tie from $i$ to $j$), $(0,1)$ (a tie from $j$ to $i$), or $(1,1)$ (a tie from $i$ to $j$ and from $j$ to $i$). Each one of these states has some probability such that the four state probabilities sum to 1 for each pair $(i,j)$. These probabilities are described in terms of five kinds of parameters: $\theta$, a base rate for edge creation; $\alpha_i$, an effect for an outgoing edge with parent node $i$; $\beta_j$, an effect for an incoming edge with child node $j$; $\rho_{ij}$, an effect of  reciprocated ties; and $\lambda_{ij}$, a normalizing constant to ensure that the four possible edge states of have probabilities summing to 1. Below, let $x_{ij} = 1$ when the edge from $i$ to $j$ exists and $x_{ij} = 0$ otherwise, and let $x_{ji} = 1$ when the edge from $j$ to $i$ exists and $x_{ji} = 0$ otherwise. Then, the edge state, $(x_{ij},x_{ji})$ between nodes $i$ andd $j$ is modeled as:
$$\log f_X((x_{ij},x_{ji})| \lambda_{ij}, \alpha_i, \alpha_j, \beta_i, \beta_j, 
\theta, \rho_{ij}) = \lambda_{ij} + x_{ij}(\alpha_i + \beta_j + \theta) + x_{ji}(\alpha_j + \beta_i + \theta) + x_{ij}x_{ji}\rho_{ij} $$
If each reciprocation parameter, $\rho_{ij}$, were unique to each edge, there would be a lack of identifiability in the model, which can be remedied by (i) not having a reciprocation effect ($\rho_{ij} = 0$ for all $i \neq j$), (ii) having a constant effect for reciprocation ($\rho_{ij} = \rho$ for all $i \neq j$), or (iii) having edge-dependent reciprocation ($\rho_{ij} = \rho + \rho_i + \rho_j$). Assuming scenario (ii), the log-likelihood function for a network $X$ can be written in exponential family form:
$$\log f_X(x | \boldsymbol{\lambda}, \boldsymbol{\alpha}, \boldsymbol{\beta}, \rho, \theta) \propto \theta \sum_{i,j} x_{ij} + \sum_i x_{i+}\alpha_i + \sum_j x_{+j}\beta_j + \rho\sum_{i,j}x_{ij}x_{ji},$$
where the minimally sufficient statistics are $x_{i+}$, the outdegree of each node $i$, $\sum_j x_{+j}$, the indegree of each node $j$, and $\sum_{i,j}x_{ij}x_{ji}$, the number of reciprocal ties in the network. This $p_1$ set of models is problematic because, as "the number of {$\alpha_i$} amd {$\beta_j$} increase directly with the number of nodes, [so] we have no consistency results for the maximum likelihood estimation" [@goldenberg09, p. 28]. An extension of the $p_1$ model is the $p_2$ model, introduced by @p2model. This model is essentially a mixed-effects model version of the $p_1$ model, with node-level fixed effects for the outgoing edge effects $\boldsymbol{\alpha}$ and the incoming edge effects $\boldsymbol{\beta}$, and edge-level fixed effects for the edge rate effects $\boldsymbol{\theta}$ and reciprocity rates $\boldsymbol{\rho}$. The random effects, added to the covariate effects for $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$, have normal distribution with mean zero and variance parameters $\sigma^2_{\alpha}$ and $\sigma^2_{\beta}$. 

The final form for ERGMs is far more general than the $p_1$ and $p_2$, and is for undirected, rather than directed, networks. There are many more possible sufficient statistics other than the outdegree, indegree, and reciprocal ties. Other graph structures that are considered are the number of triangles, $T(X) = \sum_{i \neq j \neq h} x_{ij}x_{ih}x_{jh}$, and the number of $k$-stars, $S_k(X) = \sum_i \binom{x_{i+}}{k}$, where $k = 2$ is most commonly chosen. The form of the likelihood for $X$ following this general type of ERGM is 
$$f(X|\boldsymbol{\theta}, \tau) = \exp\left(\sum_k \theta_k S_k(X) + \tau T(X) + \psi(\theta, \tau)\right),$$ 
where $\theta_k$ and $\tau$ are parameters and $\psi(\theta, \tau)$ is the normalizing constant.  A problem with this model arises when one considers the nested nature of the sufficient statistics. For example, an edge can be contained in a 2-star, which can be contained in a triangle. So, the sufficent statistics can be dependent. Despite this flaw, this type of ERGM has been studied extensively, and many methods for parameter estimation exist, for example in the \texttt{R} packages \texttt{statnet} and \texttt{sna} [@Rsoft; @statnet; @sna]. 

Another set of models includes extensions of the Erd&#x00F6;s-R&#x00E9;nyi (ER) random graph model. A natural way to extend the ER model is to vary the expected node degree of the graph. These models include the preferential attachment model or the small world models, which will be discussed further in \@ref(dynamicnets). Another model type, the exchangeable random graph model of @exchange, adds weak dependence into the edge sampling procedure.

Another area of study is community detection or blockmodels. The goal of these models is to simplify the network into a small number of "hubs" in which the members of the same hub form ties much more often with each other than with members of different hubs. These "hubs" are usually referred to as blocks or communities. Two nodes are in the same block if they are found to be "structurally equivalent," meaning that they have similar connectivity with other nodes in the network [@goldenberg09, p. 34]. The model is defined as follows: given $n$ nodes and $K$ blocks, two nodes $i,j \in \mathcal{N}$ belong to the same block $h$, $h \in \{1, \dots, K\}$ if their neighborhoods $\mathcal{C}_i \equiv \{k \in \mathcal{N} : x_{ik} = 1\}$ and $\mathcal{C}_j \equiv \{k \in \mathcal{N} : x_{kk} = 1\}$ are approximately equal. Approximately equal is vague because the metric used to compute the difference between two neighborhoods $\mathcal{C}_i, \mathcal{C}_j$ can vary depending on context. This is similar to clustering but is "a more general task than clustering" [@goldenberg09]. 

The last type static network model I'll present here is the latent space model. These models are called latent space models because they assumes that all nodes in the network can be expressed as a point in some $k$-dimensional space for "small" values of $k$ [@latentspace]. These models condition on the unknown locations of the nodes, $\mathbf{Z}_i \in \mathbb{R}^k$. Thus, the conditional probability model for the adjacency matrix $Y$, where $y_{ij} = 1$ for an edge between $i,j$ and $y_{ij} = 0$ otherwise, can be written in the form 
$$Pr(Y|\mathbf{Z}, \mathbf{X}, \boldsymbol{\Theta}) = \prod_{i\neq j} Pr(y_{ij}|\mathbf{Z}_i, \mathbf{Z}_j, \mathbf{X}_{ij}, \boldsymbol{\Theta}),$$
where $\mathbf{X}$ are covariates, $\boldsymbol{\Theta}$ are parameters, and $\mathbf{Z}$ is the matrix of node positions in $\mathbb{R}^k$. The individual edge probabilities $y_{ij}$ are modeled in terms of  $\boldsymbol{\Theta} \equiv (\alpha, \boldsymbol{\beta})$:
$$\text{logit}(Pr(y_{ij} = 1)) = \alpha + \boldsymbol{\beta}'\mathbf{X}_{ij} - |\mathbf{Z_i} - \mathbf{Z_i}| \equiv \eta_{ij}.$$
This leads to the log likelihood function, 
$$\log(Pr(Y | \boldsymbol{\eta}) = \sum_{i \neq j} (\eta_{ij}Y_{ij} - \log(1+e^{\eta_{ij}}).$$
This model can also be extended to include edge weights. 

### Dynamic Network Models {#dynamicnets}

Dynamic network models are "the neglected sibling of static network" models [@goldenberg09, p. 41]. Dynamic networks, however, are extremely important because of how realistic they are. Social networks do not form spontaneously: they evolve over time. Ties can be added and deleted, and new nodes can join the network. Modeling the process of network changes over time is more complex but ultimately more useful if done correctly. Like with static models, the literature on dynamic network models begins with fairly straightforward random graph models that are extensions of the classic Erdös-Rényi model. 

#### Quasi-Dynamic Models {#quasidynamo}

A model is quasi-dynamic if it models a static network via an underlying dynamic process. The first is the quasi-dynamic preferential attachment model of @pamodel. Given $n_0$ nodes to start, at each time point $t$ a new node is added with $n_t \leq n_0$ ties to the nodels already in the network. The $n_t$ new ties are assigned proportionally based on the degree of each existing node. It is quasi-dynamic because it is usually used to model one scale-free network oberervation. The preferential attachment model is also referred to as the "rich-get-richer" model because it results in a network where there are a few nodes with very high degree. 

Another quasi-dynamic model is the small-world model of @Watts98. Given $n$ nodes to start, each with $k$ edges that form a ring lattice (nodes layed out in a circle and connected to their $k$ closest neigbors), edges are randomly "rewired" with probability $p$. This results in networks with the small-world property: let $L$ be the average distance between any two nodes in the graph, and if the graph has the small-world property, $L \propto \log(n)$ as $n$ increases [@Watts98].

The last quasi-dynamic model is the duplication-attachment model originally studied in computer science theory in order to study the structure of the world wide web [@goldenberg09]. This model is for directed, rather than undirected graphs like the previous two models. Generally speaking, this model is constructed as follows: start with a graph $G$ with nodeset $\mathcal{N}$ and edgeset $\mathcal{E}$. At each time point $t$, one new node is added to $G$. This node is connected to a "prototype" node, call it $m$, that was selected at random from $\mathcal{N}$. In addition to this connection to node $m$ (from $m$ to the new node), there are $d$ links added from the new node to other nodes in $\mathcal{N}$. Each new link is added randomly with probability $\alpha$ to one of the nodes in $\mathcal{N}$, selected with uniform probability. With probability $1-\alpha$, the new link is directed to a node which is linked from $m$, say $\ell$ so that a path from $m$ to $\ell$ through the new node. This model can be expressed in many different ways, but I do not present them here as they are not related to the dynamic model I have chosen to study. 

#### Truly Dynamic Models {#truedynamo}

One example of truly dynamic models is the set of Markov models in discrete time. Two of these models are extensions of the ERGM model and the latent space model in time. In these scenarios, the transition probabilities, the probability of moving from the current network $x(t-1)$ to a potential future network that differs from $x(t-1)$ by one tie, $x(t)$, is similar to the likelihood of the static ERGM model:
$$Pr(x(t)|x(t-1)) = \frac{1}{\psi(\theta, \tau)} \exp\left\{ \sum_k \beta_k s_k(x(t),x(t-1))\right\}$$
The $s_k$ perform the same role that the $s_k(x)$ and $T(x)$ played in static ERGM models, but they are defined differently. For example, the density of edges of the network is defined as $s_1(x(t), x(t-1)) = \frac{1}{n-1} \sum_{i\neq j} y_{ij}(t)$ and the stability of the network is defined as $s_2(x(t), x(t-1)) = \frac{1}{n-1} \sum_{i \neq j} \left(x_{ij}(t)x_{ij}(t-1) + (1-x_{ij}(t))(1-x_{ij}(t-1))\right)$. The likelihood of the entire network through its sequence of states for times $t = 1$ through $t = T$ is therefore 

$$Pr(x(1), x(2), \dots x(T)) = \prod_{t =2}^T Pr(x(t)|x(t-1)).$$

Another discrete time model is the dynamic latent space model.  In this model, the latent positions of the nodes are allowed to change in time as follows:
$$\mathbf{Z}_{t}|\mathbf{Z}_{t-1} \sim N(\mathbf{Z}_{t-1}, \sigma^2\mathbb{I}_n).$$
The probability of a tie between any 2 nodes at time $t$, $Pr(y_{ij}(t) = 1)$, is a mixture between the probability of a "link" in the latent space as well as a noise probability, $\rho$. The link probability in the latent space is $p_{ij}^L = \left(1 + \exp(d_{ij} - r_{ij})\right)^{-1}$, where $d_{ij}$ is the Euclidean distance between nodes $i$ and $j$ in the latent space, and $r_{ij}$ is a "radius of influence" around $i$ and $j$. This radius assumes that nodes with higher degree will have higher influence in the network and will increase the probability that $x_{ij}(t) = 1$. This measure depends on the degree of both nodes:
$$r_{ij} = c\left(\max\left\{\sum_{k \neq i} x_{ik}(t), \sum_{k \neq i} x_{ik}(t)\right\} + 1\right)$$ 
where $c$ is estimated from the data and 1 is added to prevent a radius of 0 [@goldenberg09]. A kernel function, $K(d_{ij})$, is also needed. The exact form of $K$ may vary but must be non-zero only when $d_{ij} \leq r_{ij}$. So the link robability is defined as 
$$Pr(x_{ij}(t) = 1) = p_{ij}^L K(d_{ij}) + \rho(1-K(d_{ij})$$
so that the probability of a link outside the radius of influence is the constant $\rho$. The full likelihood at time $t$ is then 
$$Pr(x(t)|\mathbf{Z}_{t}) = \prod_{\{i,j : x_{ij}(t) = 1\}}p_{ij}\prod_{\{i,j : x_{ij}(t) = 0\}}(1-p_{ij}).$$

The final discrete time markov chain model is the dynamic contextual friendship model (DCFM). This model is "an attempt to capture several aspects of the complexity of the evolution of real social networks over time" [@goldenberg09, p. 53]. It relies on weighted edges, which attempt to account for the different ways people might become friends, such as at work, school, or social events. The model relies upon the existence of weighted edges which are rarely available in real data. Additionally, the SAOMs that I explore further later do not take edge weights into account, so I spend no more time on DCFMs. 

The last dynamic model is the genralized version of SAOMs, continuous time Markov Chain (CTMC) models.  These models are founded in the theory of continuous time Markove processes. Let $\{X(t), | t \in \mathcal{T}\}$ be a stochastic process in a continuous time interval $\mathcal{T}$ and finite state space $\mathcal{X}$. For any two timepoints $t_a < t_b \in \mathcal{T}$, the Markov property is defined as: 
$$Pr(X(t_b) = \tilde{x} | X(t) = x(t), \quad \forall t \leq t_a) = Pr(X(t_b) = \tilde{x} | X(t_a) = x(t_a))$$
where $\tilde{x}$ is a potential future state in $\mathcal{X}$ and $x(t_a)$ is the present, observed state of the network. Assuming this probability relies only on the length of time that passes, $t_b - t_a$, then $X(t)$ has a stationary transition distribution. Then, the transition matrix for the process $X(t)$ has entries 
$$\left[Pr(X(t_b) = \tilde{x} | X(t_a) = x(t_a))\right]_{x, \tilde{x} \in \mathcal{X}}.$$
Let $t_b - t_a = t$. Then, thanks to the stationarity of $X(t)$, the transition matrix of $X(t)$, $Pr(t)$ is equal to the matrix exponenial $\exp(t\mathbf{Q})$, where $\mathbf{Q}$ is called the *intensity matrix* in the CTMC literature. The elements of this matrix will be defined in greater detail later, but one should note that the rows of $\mathbf{Q}$ are constructed to always sum to 0, and that each element also determines the probability of changing from one state to the other as a function of time.  

For network modelling with CTMC, the state space $\mathcal{X}$ is the set of all $2^{n(n-1)}$ possible networks with $n$ nodes and directed, binary edges. Let $x$ denote the current state of the network. From this network, there are $n(n-1)$ possible networks that $x$ could become by changing just one edge variable, $x_{ij}$ to its opposite value, $1-x_{ij}$. Then, let $q_{ij}(x)$ be the propensity for for $x_{ij}$ to become $1-x_{ij}$ given $x$. This function $q_{ij}(x)$ "completely specifies the dynamics of the network model" [@goldenberg09, p. 48]. There are many forms in this family of models, which differ only in their choice of $q_{ij}(x)$. A list of some fairly simple choices for $q_{ij}(x)$ is provided in Table \@ref(tab:qfunctions). 

\begin{table}
\centering
\begin{tabular}{l c p{3in}}
\textbf{Model} & $\mathbf{q_{ij}(x) =}$ & \textbf{Brief Description} \\
Independent arc & $\lambda_{x_{ij}}$ & Edges are independent and have equal probability of changing from 0 to 1 and from 1 to 0  \\
Reciprocity & $\lambda_{x_{ij}} + \mu_{x_{ij}}x_{ji}$ & Rate of change depends on the presence of reciprocal edge. \\
Popularity & $\lambda_{x_{ij}} + \pi_{x_{ij}}x_{+j}$ & Rate of change is dependent on the indegree of the child node, $j$ \\
Expansiveness & $\lambda_{x_{ij}} + \pi_{x_{ij}}x_{i+}$ & Rate of change is dependent on the outdegree of the parent node, $i$
\end{tabular}
\caption{(\#tab:qfunctions) Some propensity functions to describe the network dynamics in CTMC models.}
\end{table}

Additional definitions of $q_{ij}(x)$ are more complicated. These next set of models rely on two different underlying mechanisms: one that determines which node is given the opportunity to change and one that determines the propensity of change. First, I consider the subset of models with edge-oriented dynamics. Let $x(i\leadsto j)$ denote the network that differs from $x$ by just one node, $x_{ij}$, which takes on the value $1-x_{ij}$ in $x(i \leadsto j)$. Then, write the probability that node $x_{ij}$ changes to $1-x_{ij}$ as 
$$p_{ij}(x) = \dfrac{\exp(f(\boldsymbol{\beta}, x(i \leadsto j)))}{\exp(f(\boldsymbol{\beta}, x))+\exp(f(\boldsymbol{\beta}, x(i \leadsto j)))},$$
where $f(\boldsymbol{\beta}, x) = \sum_k \beta_k s_k(x)$ is called the potential or objective function [@goldenberg09]. The $\beta_k$ are parameter values associated with the network statistics that are also used in ERGMs. For more definitions of the possible $s_k(x)$, see Table \@ref(tab:effects). The opportunity for change in this model is controlled by a constant rate parameter, $\alpha$. The wait time between a change of any edge in the network is exponentially distributed with parameter $\alpha$. So, the function $q_{ij}(x)$ is defined as $\alpha p_{ij}(x)$. 

The next subset of models rely on node-oriented dynamics. These are very similar to the edge-oriented dynamics but the rate parameter and propensity to change are defined with respect to the nodes instead of the edges. Now, each node has its own rate at which it gets an opportunity for change, $\alpha_i$. Additionally, the objective function is defined for each node, $f_{i}(\boldsymbol{\beta}, x) = \sum_k \beta_k s_{ik}(x)$. This changes the definition of the statistics used slightly, from global statistics to local statistics with ego node $i$. Thus, the propensity function becomes $q_{ij}(x) = \alpha_i p_{ij}(x)$. 

Finally, there is a way to combine edge and node dynamics so that the propensity function becomes a hybrid of the prior two: $q_{ij}(x) = \alpha p_{ij}(x)$ where $\alpha$ is a constant rate of edge change, while $p_{ij}$ is the propensity to change edge $x_{ij}$ using the node-oriented objective function $f_i(\boldsymbol{\beta},x)$. This is the subset of models to which the stochastic actor-oriented models belong. So I describe these in great detail in Section \@ref(saoms). 

## Stochastic Actor-Oriented Models for Longitudinal Social Networks. {#saoms}

The phrase Stochastic Actor-Oriented Model is quite a mouthful, but it contains most of the important information about the model. First, the model is changing in time in order to accomodate for observations from the same network made at different points in time. Second, it allows for changes in network structure due to actor-level covariates. These two properties are crucial to understanding networks as they exist naturally. Most social networks are ever-changing as relationships decay or grow, and most actors (or nodes) in social networks have inherent properties that could affect how they change their place within the network. 

### Terminology, Notation, and Mathematical Definition of SAOMs {#saomsnote}

A longitudinal network is a network consisting of the same set of $n$ nodes that is changing over time, and is observed at $M$ discrete time points, $t_1, \dots, t_M$. Denote these network observations $x(t_1), \dots, x(t_M)$. The SAOM assumes that this longitudinal network is embedded within a continuous time markov process (CTMP), call it $X(T)$. This process is almost entirely unobserved. The process $X(T)$ theoretically exists outside of the range of observation, but for simplicity of notation, assume that the beginning of the process, $X(0)$ is equivalent to the first observation $x(t_1)$, while the end of the process $X(\infty)$ is equivalent to the last observation $x(t_M)$.  The observations $x(t_1), \dots, x(t_M)$ are observed states of the process, $x(t_1) \equiv X(0), x(t_2) \equiv X(T_{t_2}), \dots, x(t_{M-1}) \equiv X(T_{t_{M-1}}), x(t_M) \equiv X(\infty)$, but the time points $t_m$ and $T_{t_m}$ for $m = 2, \dots M-1$ are not equivalent. The process $X(T)$ is a series of single tie changes, in which one actor at a time is given the opportunity to add or remove one outgoing tie.  These opportunities for change can arise at a different rate for each actor, and the overall rate of change, the distribution of the waiting times that *any* actor will be given the opportunity to change is a function of all actors' rates. Additionally, once an actor is given the chance to change a tie, it tries to maximize a sort of utility function based on the current and potential future states of the network. These functions are described in detail in subsections \@ref(saomrate) and \@ref(saomobjective). 

### The Rate Function {#saomrate}

In the network $x$ and for each actor $i$ in this network, the rate function is most generally denoted $\lambda_i(\alpha, \rho, x, m)$, which dictates how quickly actor $i$ gets opportunities to change one of its ties, $x_{ij}$ in the time period $t_{m} \leq T < t_{m+1}$. In this function, $\alpha$ and $\rho$ are parameters, $x$ is the current network state at time $m$. Note that $x \in \mathcal{X}$, where $\mathcal{X}$ is the space of possible networks given the $n$ nodes in the network, and that $|\mathcal{X}| = 2^{n(n-1)}$. We assume that the actors $i$ are conditionally independent given their current ties, $x_{i1}, \dots, x_{in}$. This assumption gives the rate function for the whole network as $\lambda(\alpha, \rho, x, m) = \sum_i \lambda_i(\alpha, \rho, x, m)$. For any time point, $T$, where $t_m \leq T < t_{m+1}$, the waiting time to the next change opportunity by actor $i$ has distribution *Exponential*$(\lambda_i\alpha, \rho, x, m))$ in order to achieve the memorylessness property of a Markov process. Thus, the waiting time to the next change opportunity by *any* actor in the network has distribution *Exponential*($\sum_i \lambda_i\alpha, \rho, x, m)$). There are many possibilities for the rate function, $\lambda_i$. The simplest is that it is constant over all actors and all unobserved timepoints between observations $x(t_{m-1})$ and $x(t_m)$, $\lambda_i(\alpha, \rho, x, m)) = \alpha_m$. The rate function can also depend on covariate values, call them $\mathbf{z}_{i}(t_m)$, of the actors or structural network elements such as outdegree, or both. For instance, assume $\lambda_i(\alpha, \rho, x, m)) = \lambda_{i1}\lambda_{i2}\lambda_{i3}$, where $\lambda_{i1}$ is constant over $m$, $\lambda_{i2}$ depends on the actor covariates, and $\lambda_{i3}$ depends on a structural network property for node $i$. $\lambda_{i2}$ might be written as $\lambda_{i2} = \exp\left(\sum_h \rho_h z_{ih}(t_m)\right)$, where there are $h = 1, \dots, H$ actor covariates of interest, each with their own parameter $\rho_h$. $\lambda_{i3}$ can be written as a function of the outdegree of node $i$, denoted $x_{i+}$ with its own parameter $\alpha_{H+1}$, so that, for example, $\lambda_{i3} = \frac{x_{i+}}{n-1}\exp(\alpha_{H+1}) + \left(1-\frac{x_{i+}}{n-1}\right)\exp(-\alpha_{H+1})$. When $H=0$, this form of $\lambda_{i3}$ is equivalent to the model proposed by @wassermanrecip, which is one of the first models proposed for modeling dynamic networks as continuous-time Markov processes [@snijders01].  Given that a change occurs, the probability that actor $i$ is given the power to change a tie is $$\frac{\lambda_i(\alpha, \rho, x, m))}{\sum_i \lambda_i(\alpha, \rho, x, m))}$$.
 
### The Objective Function {#saomobjective} 

Thanks to the conditional dependence assumptions in the model, we can consider the objective function for each node separately, since only one tie from one node is changing at a time. The objective function is written as $f_i(\boldsymbol{\beta}, x) = \sum_k \beta_k s_{ik}(x, \mathbf{Z}), x \in \mathcal{X}$ and $\mathbf{Z}$ the matrix of covariates. The vector $\boldsymbol{\beta}$ are the parameters of the model and $x$ is any possible state of the network. Given the focal or ego node, $i$, there are $n$ possible steps for the actor $i$ to take: either one of all current ties $x_{ij}$ will be destroyed, a new tie will be created, or no change will occur. 

The parameters, $\beta$, are attached to various actor-level network statistics, $s_{ik}(x)$. There are always at least two parameters, $\beta_1$ for the outdegree of a node, and $\beta_2$ for the number of reciprocal ties held by a node [@snijders01 p. 371]. There are many possible parameters $\beta$ to add to the model. They can be split up into two groups: first, the structural effects, which only depend on the structure of the network. The inclusion of these effects has origin in the ERGMs discussed previously for static networks in section \@ref(staticnets). These effects are written in terms of the edge variables $x_{ij}$, for $i \neq j$. The second set of effects are the actor-level or covariate effects. These effects also depend on the structure of the network. They are written in terms of $x_{ij}$ but also in terms of the covariates, $\mathbf{Z}$. A table of some possible structural and covariate effects is given in \@ref(tab:saom-effects). 

\begin{table}
\caption{(\#tab:effects) Some of the possible effects to be included in the stochastic actor-oriented models in RSiena. There are many more possible effects, but we only consider a select few here. For a complete list, see the RSiena manual [@RSienaManual].}
\centering
\begin{tabular}{ll}
\textbf{Structural Effects} \\
outdegree  & $s_{i1}(x) = \sum_j x_{ij}$ \\
reciprocity  & $s_{i2}(x) = \sum_j x_{ij}x_{ji}$ \\
transitive triplets  & $s_{i3}(x) = \sum_{j,h} x_{ij}x_{jh}x_{ih}$ \\
\textbf{Covariate Effects}\\
covariate-alter  & $s_{i4}(x) = \sum_j x_{ij}z_j$ \\
covariate-ego  & $s_{i5}(x) = z_i\sum_j x_{ij}$ \\
same covariate & $s_{i6}(x) = \sum_j x_{ij} \mathbb{I}(z_i = z_j)$ \\
jumping transitive triplets  & $s_{i7}(x) = \sum_{j \neq h} x_{ij}x_{ih}x_{hj} \mathbb{I}(z_i = z_h \neq z_j)$
\end{tabular}
\end{table}

When node $i$ is given the chance to change a node, we assume that they wish to maximize the value of their objective function $f_i(\boldsymbol{\beta}, x)$ plus a random element, $U_i(x)$, where the $U_i(x)$ are from "the type 1 extreme value distribution (or Gumbel distribution) with mean 0 and scale parameter 1" [@snijders01, p. 368]. This distribution, which is also known as the log-Weibull distribution, has probability distribution function, using $\mu$ for the mean parameter and $\sigma$ for the scale parameter, of

$$f(u|\mu, \sigma) = \frac{1}{\sigma}\exp\left\{-\left(\frac{x-\mu}{\sigma} + e^{-\frac{x-\mu}{\sigma}}\right)\right\}.$$

Using this distribution is convenient because it allows the probablity the actor $i$ chooses to change its tie to actor $j$ in terms of the objective function alone. Let $p_{ij}(\boldsymbol{\beta}, x)$ be this probability. Next, write the network $x$ in its potential future state, where the tie $x_{ij}$ has changed to $1-x_{ij}$, as $x(i \leadsto j)$. Then, the probility that the tie $x_{ij}$ changes is 

$$p_{ij}(\boldsymbol{\beta}, x) = \dfrac{\exp\left\{f_i(\boldsymbol{\beta}, x(i\leadsto j))\right\}}{\sum_{h \neq i} \exp\left\{f_i(\boldsymbol{\beta}, x(i \leadsto h))\right\}}$$

### A SAOM as a CTMP {#saomctmp}

In order to fit this model definition back into the original context of the CTMP described in section \@ref(truedynamo), it must be written in terms of its intensity matrix, $\mathbf{Q}$.  This matrix describes the rate of change between states of the process. For networks, there are a very large number of possible states, $2^{n(n-1)}$, so the intensity matrix is a square matrix of that dimension. But, thanks to the property of SAOM that the states are allowed to change only one tie at a time, there are only $n$ possible states given the current state, $n-1$ of which are uniquely determined by the node $i$ that is given the opportunity to change. Thus, the intensity matrix $\mathbf{Q}$ is very sparse, with only $n(n-1) + 1$ non-zero entries in each row. Note that $n(n-1)$ of these represent the possible states that are one edge different from a given state, and the additional non-zero entry is for the state to remain the same. All other entries in a row are zero because those column states cannot be reached from the row state by just one change as dictated by the SAOM. The entries of $\mathbf{Q}$ are defined as follows: let $b \neq c \in \{1, 2, \dots, 2^{n(n-1)} \}$ be indices of two different possible states of the network, $x^b, x^c \in \mathcal{X}$.  Then the $bc^{th}$ entry of $Q$ is:
\[ q(x^b, x^c) = \begin{cases} 
      q_{ij}(\alpha, \rho, \boldsymbol{\beta}, x^b) = \lambda_i(\alpha, \rho, x^b, m)p_{ij}(\boldsymbol{\beta}, x^b) & \text{if } x^c \in \{x^b(i \leadsto j) | \text{ any } i \neq j \in \mathcal{N}\} \\
      0 & \text{if } x^c \text{ differs from } x^b \text{ by more than 1 tie} \in \mathcal{N} \\
      -\sum_{i\neq j} q_{ij}(\alpha, \rho, \boldsymbol{\beta}, x^b)  & \text{if } x^b = x^c 
   \end{cases}
\]

Thus, the rate of change between any two states that differ by only one tie, $x_{ij}$, is the product of the rate at which actor $i$ gets to change a tie and the probability that the tie that will change is the tie to node $j$.^[Just to be clear, the change is from $x^b_{ij}$ to $x^c_{ij} = 1 - x^b_{ij}$.] Furthermore, the theory of continuous time Markov chains gives that the matrix of transition probabilities between observation times $t_{m-1}$ and $t_{m}$ is dependent only on the difference between timepoints, $t_m - t_{m-1}$ and is equal to $e^{(t_m - t_{m-1})\mathbf{Q}}$, where $\mathbf{Q}$ is the matrix defined above and $e^X$ for a real or complex square matrix $X$ is equal to $\sum_{k=0}^{\infty} \frac{1}{k!} X^k$.


### Model Fitting for SAOMs

Stochastic actor-oriented models are "too complicated for the calculation of likelihoods or estimators in closed form, but they represent stochastic processes which can be easily simulated" [@snijders2010, p. 568]. Thus, maximum likelihood estimation of the parameters in SAOMs is done via Markov Chain Monte Carlo (MCMC) approximation. The algorithm presented here was presented first in @snijders2010. 

First, some definitions and notation are needed. Let $x(t_m)$ denote the observed state of the network at time $t_m$. Then, let $\mathcal{A}(x(t_m) = \mathcal{A}_1(x(t_m)) \cup \mathcal{A}_2(x(t_m)) \cup \cdots \cup \mathcal{A}_n(x(t_m))$ denote the set of all networks that are one tie away from the current state $x(t_m)$. For all nodes $i = 1, \dots, n$, $\mathcal{A}_{i}(x(t_m)) \subset \mathcal{X}$ is formally defined as $$\mathcal{A}_{i}(x(t_m)) = \left\{x(t_m) \cup \{x \in \mathcal{X} | x_{ij} = 1 - x_{ij}(t_m) \text{for only one } j \neq i \in \mathcal{N}\}\right\}.$$ 
Next, let $x(t_{m+1})$ denote the next observed network state. When moving from $x(t_m)$ to $x(t_{m+1})$, there are many possible unobserved steps in between. Moving from the observation $x(t_{m-1})$ to the observation $x(t_m)$ requires $C$ changes or steps in the Markov process $X(t)$ where $C = \sum_{i,j \in \mathcal{N}} |x_{ij}(t_m) - x_{ij}(t_{m-1})|$. Note that the observed network change from $x(t_{m-1})$ to $x_(t_m)$ is conditionally independent of all other network observations given $x(t_{m-1})$. Denote the $C$ timepoints in the the Markov process that correspond to the unobserved changes in the network as $T_1, T_2, \dots, T_{C}$ and define $T_0 = t_{m-1}$ and $T_C \leq t_{m} < T_{C+1}$. For each timepoint $T_c$, for $c = 1, \dots c$, there is a single actor, denoted $I_c$ that gets an opportunity to change at this timepoint. This actor changes one of its ties to one node, $J_c$, i.e. $X_{I_c J_c}(T_c) = 1 - X_{I_c J_c}(T_{c-1})$. If there is no change, $I_c = J_c$. Formally, the pair $(I_c,J_c)$ is the only $(i,j)$ pair for which $x_{ij}(T_{c-1}) \neq x_{ij}(c_r)$ if such a pair exists, and $(I_c, J_c) = (I_c, I_c)$ otherwise. The triplet $(T_c, I_c, J_c)$ forms a stochastic process for $c = 1, \dots, C$ that, given the prior observation, $x(t_{m-1})$ for $m = 2, \dots, M$, completely determines $X(T)$ for $t_{m-1} < t < t_m$. Next, define the set of augmenting data as $\{C \cup (I_c, J_c): c = 1, \dots, C\}$ Note the timepoints $T_c$ are left out of the augmenting data. Also define the sample path as the stochastic process $\mathbf{V} = ((I_c, J_c):c = 1, \dots, C)$. Note that the elements of $V$ where $I_c = J_c$ are redundant. However, they are kept in the process because they help with computation of the likelihood. At each step in the sample path, the networks $X(T_{c-1})$ and $X(T_{c})$ differ by only one tie, $X_{I_c J_c}$. The distribution of the sample path can then be written down as follows: 
$$ f_{sp}(V|\alpha_m, \boldsymbol{\beta}, x(t_1)) = Pr(T_c \leq t_m < T_{C+1} | x(t_1), V, \alpha_m, \boldsymbol{\beta}) \times \prod_{c=1}^C q_{I_c J_c}(\alpha, \rho, \boldsymbol{\beta}, X(T_c)). $$
The first component, $Pr(T_C \leq t_m < T_{C+1} | x(t_1), V, \alpha, \beta)$ is the probability that your next network observation at time point $t_m$ comes *before* the next change in the continuous time Markov chain, $X(T_{C+1})$. Assuming the rate function $\lambda_i(\alpha_m, \rho, x)$ as defined in Section \@ref(saomrate) is constant, $\lambda_i(\alpha_m, \rho, x) = \alpha_m$, for all nodes $i = 1, \dots, n$ and each timepoint $m = 2, \dots, M$ this probability can be written as:
$$\kappa(\alpha_m, x(t_{m-1}), \mathbf{V}) = \exp(-n\alpha(t_{m} - t_{m-1}))\frac{n\alpha(t_m - t_{m-1})^C}{C!}.$$
There is a more general formulation of this probability presented in @snijders2010 for non-constant rates of change, but I do not present it here because I do not have non-constant rates in any of the SAOMs I work with in Chapters \@ref(ch1) and \@ref(ch2). The second component, $\prod_{c=1}^C q_{I_c J_c}(\alpha_m, \rho, \boldsymbol{\beta}, X(T_c))$, is the product of the corresponding values of the intensity matrix $\mathbf{Q}$ for the sample path $\mathbf{V}$, where $\mathbf{Q}$ is as defined in Section \@ref(saomctmp).   

#### Method of Moments Estimation

Let $\theta = (\boldsymbol{\alpha}, \boldsymbol{\beta})$ be the parameter vector. $\theta$ is of length $L = M-1+K$, where $M$ is the number of network observations and $K$ is the number of parameters included in the objective function $f_{i}(\boldsymbol{\beta}, x)$. Let $Z = (C_1, \dots, C_M, S_{1k}, \dots, S_{Mk})$ denote the vector of statistics corresponding to the values of $\theta$, where $C_m = \sum_{i\neq j } |x_{ij}(t_{m+1}) - x_{ij}(t_{m})|$ and $S_{mk} = \sum_i s_{ik}(x(t_{m+1}))$ for $m = 1, \dots, M-1$. 

The method of moments estimator of $\theta$ is the solution to $E_{\theta}[Z] = z$ where $z$ are the observed values of $Z$ from $x(t_1), \dots, x(t_M)$.  The estimate $\hat{\theta}$ can be separated into the vectors $\hat{\boldsymbol{\alpha}}$ and $\hat{\boldsymbol{\beta}}$, the solutions to the system of equations $E_{\boldsymbol{\alpha}}[C_m|x(t_m)] = c_m$ and $\sum_{m = 1}^{M-1} E_{\boldsymbol{\beta}}[S_{mk}|x(t_m)] = \sum_{m=1}^{M-1} s_{mk}$ [@snijders01]. 

These moment equations are often not able to be calculated explicitly. Because of this, random simulation of networks with the desired distribution can be used in Markov Chain Monet Carlo simulation of the moment estimates. The updating step of the simulation is, for iterations $b = 1, \dots, B$: 
$$\theta^{(b+1)} = \theta^{(b)} + a_b D_0^{-1}(Z_b - z)$$
where $Z_b$ is drawn from the distribution of the model under $\theta = \theta^{(b)}$, $z$ are the observed statistics, $D_0$ is a positive diagonal matrix, usually the identity, and $a_b$ is called the *gain sequence* and is a sequence of positive values that approach 0 as $b\to \infty$ at about the same rate as $b^{-r}$ for some $0.5 < r < 1$. The method of moments estimator, $\hat{\theta}^{(1)}$ is then an average of the $B$ iterations, $\hat{\theta}^{(1)} = \frac{1}{B}\sum_{b = 1}^B \theta^{(b)}$. It must be the average in order to obtain opimal convergence [@snijders01]. 

#### Maximum Likelihood Estimation 

Sketch of Algorithm:
\begin{enumerate}
\item Use the first network observation, $x(t_1)$, as a starting value. All analysis proceeds conditioning on $x(t_1)$.  
\item For $m = 2, 3, \dots, M$ where $M$ is the total number of observed networks, augment the observed data with random draws from the sequence of intermediate steps in the Markov process, $X(T)$, that could have led from $x(t_{m-1})$ to $x(t_m)$. i.e. draw from the set {\small $$\{(X(T_1), \dots, X(T_{C-1}))' | X(T_1) \in \mathcal{A}(x(t_{m-1})) \& X(T_2) \in \mathcal{A}(X(T_1)) \& \cdots \& x(t_{m}) \in \mathcal{A}(X(T_{C-1})) \}$$ } where $C = \sum_{i,j \in \mathcal{N}} |x_{ij}(t_m) - x_{ij}(t_{m-1})|$. Note that $C$ in the number of single edge changes needed to get from $x(t_{m-1})$ to $x(t_m)$, so $C-1$ is the number of intermediate networks. These draws can be simulated using a Metropolis-Hastings algorithm. 
\item Use the draws from 2 as updates in a Robbins-Monro algorithm [see @robbinsmonro] to find the solution of the likelihood equation. 
\end{enumerate}

Full Iterative Algorithm: For each iteration $b = 1, 2, \dots, B$
\begin{enumerate}
\item For each $m = 2, \dots, M$, make a large number of Metropolis-Hastings steps of the following form.  Let $\underline{v} = ((i_1, j_1), \dots, (i_C, i_C))$ be a given path from $x(t_{m-1})$ to $x(t_m)$ in the whole possible set of paths $\mathbf{V}$. Then propose a new path, $\tilde{\underline{v}}$ from the proposal distribution that consists of all of the possible small changes: 
  \begin{enumerate}
  \item "Paired Deletions" - Of all pairs of indices $c_1, c_2$ such that $(i_{c_1}, j_{c_1}) = (i_{c_2}, j_{c_2})$, $i_{c_1} \neq j_{c_1}$, randomly select a pair $(c_1, c_2)$ and delete both from the current path.
  \item "Paired Insertions" - Randomly select an edge $(i,j) \in \mathcal{b} \times \mathcal{b}$ with $i \neq j$. Randomly choose 2 indices, $c_1, c_2$. Insert $(i,j)$ immediately before $c_1$ and $c_2$.  
  \item "Single Insertions" - At a random place in the current path, insert $(i,i)$ for a random $i \in \mathcal{b}$.
  \item ``Single Deletions" - Of all elements in the current path that satisfy $i_c = j_c$, randomly delete one of them. 
  \item ``Permutations" - For randomly chosen $c_1 < c_2$, where $c_2 - c_1$ is bounded from above by some smallish number to avoid lengthy computation (tuning parameter?), the segment of consecutive elements $(i_c,j_c)$, $r = c_1, \dots, c_2$ is randomly permuted. 
  \end{enumerate}
Denote the proposal probabilities $u(\tilde{\underline{v}} | \underline{v})$ and the target probabilities $p(\underline{v})$. The target distribution is $p(\underline{v}) \propto f_{sp}(\underline{v} | \alpha, \beta, x(t_{m-1}))$. Then the acceptance probability for a proposal path $\tilde{\underline{v}}$ and a current path $\underline{v}$ is: $\min \left\{ 1, \frac{p(\tilde{\underline{v}})u(\underline{v}|\tilde{\underline{v}})}{p(\underline{v})u(\tilde{\underline{v}}| \underline{v})}\right\}$. The series of M-H steps will result in a new set of augmenting data, $(v^{(b)}) = (v_2^{(b)}, \dots, v_M^{(b)})$. 
\item Let $\theta = (\alpha, \boldsymbol{\beta})$. Compute 
  $$ S_{XV}(\hat{\theta^{(b)}}; x(t_{m-1}), v^{(b)}) = \sum_{m=2}^M S_m(\hat{\theta^{(b)}}; x(t_{m-1}), v_m^{(b)}) $$
$S_{XV}(\hat{\theta^{(b)}}; x, v^{(b)})$ is the complete data score function. $S_m(\hat{\theta^{(b)}}; x(t_{m-1}), v_m^{(b)}) = \frac{\partial \log p_m(v_m; \theta | x(t_{m-1}))}{d\theta}$ is the total data score function at step $m$. $p_m$ is $p_{sp}(v_m; \theta | x(t_{m-1}))$, the probability of the sample path $v_m$. 
\item Update $$\theta^{(b+1)} =(\alpha^{(b+1)}, \boldsymbol{\beta}^{(b+1)}) = \theta^{(b)} + a_b D^{-1} S_{XV}(\hat{\theta^{(b)}}; x, v^{(b)})$$
where $D$ is a MC estimate of the complete data observed Fisher information matrix, $D_{XV}(\theta) = -\frac{\partial S_{XV}(\theta: x, V)}{\partial \theta}$ estimated for evaluated at the starting value of $\theta$, $\theta^{(1)}$. A good starting value is the method of moments estimator, $\hat{\theta}^{(1)}$.
\item Calculate $\hat{\theta} = (B - b_0 + 1)^{-1} \sum_{b = b_0}^B \theta^{(b)}$ for some large value $b_0 < B$. 
\end{enumerate}

#### Model Selection and Testing for SAOMs

A likelihood ratio test was also developed in @snijders2010, but it has yet to be implemented in the software RSIENA for parameter estimation of SAOMs. Tests of the elements of $\boldsymbol{\beta}$ are, however, availabile in RSIENA. Both $t$-tests and Wald-type tests are implemented. A goodness-of-fit test is also implemented, but it only assesses the fit of a model with respect to the "auxiliary statistics of networks [...] that are not explicitly fit by a particular effect" [@RSienaManual, p. 53]. It is this lack of goodness-of-fit testing that led my research down the path of applying visual inference principles and protocols to hypothesis testing for SAOMs.  

## What is Visual Inference?

Viewing plots of data is an important part of exploratory data analysis (EDA) and of model diagnostics (MD). In EDA, plots guide the analyst on their quest to choose a model, while in MD, plots help the analyst determine if the model chosen is appropriate. In EDA, the analyst may notice that a covariate is strongly correlated with the dependent variable by drawing a scatterplot, leading the analyst to choose a simple linear model. But in MD, the analyst could later notice a pattern in the residuals plotted against the covariate, indicating that the variance of the dependent variable is not constant across changing values of the covariate. These steps of EDA and MD have become so engrained in statistical practice that they are taught in introductory statistics courses. But, how can we formalized this visual discovery process?

### A Formal Definition and Construction

The idea of visual inference was first introduced in @Bujaetal. In this seminal work, the authors outline two protocol for visual tests of hypotheses, the "Rorschach" the "lineup". The former allows one "to measure a data analyst’s tendency to overinterpret plots in which there is no or only spurious structure," while the latter has the viewer "identify the plot of the real data from among a set of decoys [...] under the veil of ignorance" [@Bujaetal, p. 4368-9]. 

They begin by formalizing the definition of the set of discoverable (i.e. visible) features of a plot as a set of test statistics, denoted $T^{(i)}(\mathbf{y})(i \in I)$. The value $\mathbf{y}$ is the data in the plot, and the set $I$ is the hard-to-define set of all possible visual features one could discover in a plot. Then they consider a general null hypotheses scenario, $H_0$, from which the data could have arisen. Samples are then taken from this null model and the same plot is made for the samples as was made for the data. These plots are called "null plots" while the other is the "data plot". The idea is that if an "analyst" sees a feature in the data, and also in the null plots, then the data cannot be said to come from a different scenario than $H_0$. 

Generating samples from $H_0$ is not trivial. The authors provide three types of sampling available for creating the null plots: conditional sampling given a minimally sufficient statistic, parametric bootstrap sampling, and Bayesian posterior predictive sampling. [@Bujaetal p. 4367]. Once the null plots are generated, they are presented to an analyst through the Rorschach and lineup protocols.  

In the Rorschach protocal, the analyst looks at a series of plots and describes any features or structures that stand out to them. These plots will all be null plots, but the analyst should not know this. The protocol administrator should also not know whether or not the data plot is in the series of plots. Then, these results are examined by the researcher, who determines what tendency the analyst have to "over-interpret" plot structure. 

In the lineup protocol, the analyst looks at $M$ plots that are laid out in a grid. $M - 1$ of these plots will be null plots, while one is the data plot. For $M=20$, the probability of choosing the data plot from among the null plots is 0.05, providing us with an inferentially valid $p$-value of $\alpha=0.05$. The lineup protocal has several special features. First, there is no need for pre-specification of the visual feature the analyst should identify. They can simple be asked to pick the most different or most special plot. Second, the analyst can self-administer the lineup once, thereby becoming a data point in their own experiment. Next, it is possible that 2 or more plots can be selected from among the $M$ plots, as ranked data methods can be used for data analysis. Finally, the procedure can have as many repetitions as possible, as long as the analysts are independently selected and have not previously viewed the plot of the data. This can lead to extremely small $p$-values for inference, with the smallest possible being $0.05^K$ for $K$ analysts, assuming all $K$ selected the data plot from the lineup. Formally, the $p$-value of a lineup of size $M$ evaluated by $K$ analysts is 
$$Pr(X \geq x) = 1 - Binom_{K, \frac{1}{M}}(x-1)$$
where $X$ is the number of analysts who correctly identify the data plot, $x$ the observed value $X$ for an experiment, and $Binom_{K, \frac{1}{M}}(x)$ is the probability mass function of the binomial distribution with $K$ trials and probability of success $\frac{1}{M}$ evaluated at the observed $x$. Type I error, the probability that a test rejects $H_0$ when it is true, is also formally defined as $Pr(X \geq x_{\alpha})$, where $x_{\alpha}$ is the number of observers picking the data plot needed so that $P(X \geq x_{\alpha}|H_0)$ is less than or equal to the chosen value of $\alpha$. The type II error, the probability that $H_0$ is not rejected when it is not true, is then $P(X < x_{\alpha})$, where $X$ and $x_{\alpha}$ are defined as above. Additionally, the power of the test given the true state, either when $H_0$ is true or when it is not, is the probability that the test rejects $H_0$. When $H_0$ is true, the power is $1- Binom_{K, \frac{1}{M}}(x_{\alpha} - 1)$. If $H_0$ is not true, the power depends on the specific true state (alternative hypothesis) chosen [@linearvizinf]. 

The type of plots shown in visual inference will vary based on the context of the research question and null hypothesis of interest. For example, scatterplots can be shown to test for independence of two variables or for clustering; histograms can be shown to test for distribution of a variable; time series plots can be shown to test for trends; residual plots can be shown to test for presence of structure the model misses; and smoothers can be shown to test for differences in trends between groups. All of these examples are discussed in detail in @Bujaetal. 

Additional detail to consider is the importance of varying skillsets of analysts, and the effectiveness of each analyst at selecting the data lineup. Some analysts, especially when doing experimentation, will be more visually inclined, or more analytically inclined, and these individual differences can affect the success rate of an analyst, and the rate of identification may need to be modified to account for these differences. 

### Applications of Visual Inference

There have been two distinct areas of application of visual inference since @Bujaetal. The first is true application of the methodology, while the second is understanding the methodology via application of the protocols. In both applications usually rely on the Amazon Mechanical Turk service [@turk] or other similar services to show lineups to many participants from different backgrounds quickly.  

In true applications, researchers have one or more alternative hypotheses and corresponding nulls on which they perform visual inference tests to show many participants of different backgrounds the lineups. One such paper, @Loy2016, considers the visual inference tests for normality via lineups of Q-Q plots and compares these tests to traditional statistical normality tests. The authors found that visual inference used in this way is a more powerful test for normality than classical tests [@Loy2016].  In another direct application, @Zhao13 use visual inference to establish the existence of a structrue in the RNA sequence of soybean plants where different treatments and conditions alter the gene expression. Yet another application is that of @Hofmann12, in which the authors use visual inference to determine which view of a dataset to present so that the important data properties are communicated most accurately and efficiently.

The second type of application, understanding the methodology through application is the type that I pursue in \@ref(ch2). One such instance of this type of application is @Chowd14, in which visual inference is used to better understand problems that arise when viewing high dimension, low sample size data. A second application is that of @Loy2015 in which the authors use visual inference to determine hierarchical model misspecification. In both of these applications, visual inference is used to discover more about the models or structures under investigation. This is how I intend to use visual inference for SAOMs. By using the lineup protocol, I hope to learn more about the effects of parameter selection on SAOMs, and order to do this, I also need to have tools to visualize the networks simulated from SAOMs. 

## Network Visualization

Network visualization, also called network mapping, is a very well-established subfield of network analysis. As networks have such a non-traditional data structure, visualization has always been of the utmost importance to understanding the structre of a network.

### Layout Algorithms

The key difficulty with network visualization that does not arise with most other types of data visualization is the lack of a well-defined axis. This is not something one has to think hard about for most data visualizations. If the variables are numerical, histograms, scatterplots, or time series plots are straightforward to construct: one variable on the x-axis, another on the y-axis in 2D Euclidean space. If the variables are categorical, bar charts and mosaic plots can be constructed in this same space. If the data are spatial, there is a well-defined space In pretty much any case, the location and labels of the data and axes can be defined with very little struggle. With network data, however, this is a more difficult problem. 

Network visualizations are made by representing nodes with points in 2D Euclidean space, just like one would with any other data set, and then by representing edges by connecting the points with lines if there is an edge between the two nodes. But, because there is no natural placement of the points, a random placement is used, then adjusted iteratively via a layout algorithm, of which there are many kinds. I will focus on the 2D layout algorithms only because I work later with the `ggplot2` package to visualize networks, and this package only has 2D drawing capabilities.

Some layout algorithms were designed to mimic physical systems, drawing the graphs based on the "forces" connecting them. The network's edges act as springs pushing and pulling the nodes in 2D space. Some force-directed layout algorithms are:

- Kamada-Kawai: first introduced in @kamadakawai. Has "symmetric drawings, a
relatively small number of edge crossings, and almost congruent drawings of isomorphic graphs" [@kamadakawai, p. 15]
- Fruchterman-Reingold: first introduced in @fruchterman-reingold. Primary advantage is speed over Kamada-Kawai [@fruchterman-reingold, p. 1161].
- Spring embedding: first introduced in @springs. Other force-directed layouts are refinements of this original algorithm.
- Target diagram: nodes placed in concentric circles with hig-centrality nodes placed nearer to the center of the circle. First introduced in @Brandes2003.

Other layout algorithms depend on the mathematical properties of the network's adjacency matrix or some other function or propterty of the network. Algorithms of this kind are:

- Eigen: node placement is based on the eigenvalues of the adjacency matrix
- Hall: node placement is based on the last two eigenvectors of the Laplacian of the adjacency matrix
- Multidimensional Scaling (MDS): node placement is based on metric multidimensional scaling of a given distance matrix. Distance metric can vary.
- Principal Coordinates: node placement is based on the eigenvalues of a given covariance or correlation matrix. 

Some layout algorithms only exists for certain types of networks:

- Reingold-Tilford: for trees
- Sugiyama: for layerd directed acyclic graphs

Finally, some layout methods just place the nodes randomly or in a simple ordering:

- Random: places nodes randomly according to some distribution, usually uniform or some Gaussian distribution.
- Grid: places nodes on a 2D grid
- Circle: places nodes in a circle in numerical order by ID number

These layout algorithms have been provided in several R packages for network visualization. Another important aspect of network visualization is the addition of varirable information into the properties of the points and segments of the network visualization. For example, the size of the point, the width of the line, and the color of these these can all be mapped to the points and segments making up the network visualization. This is discussed further in Section \@ref(iloveggplot2). 

### R Packages

There is a multitude of R packages that exist for network analysis, and many, if not most, of them contain some sort of built-in functionality for visualizing networks. The most popular of these is probably the `igraph` package by @igraph. This package is extensive, and contains much more than methods for network visualization. It contains tools for both 2D and 3D visualization of networks. The 2D layouts it contains are `random`, `circle`, `star`, `grid`, `graphopt`, `bipartite`, `fruchterman_reingold`,`kamada_kawai`, `mds`, `grid_fruchterman_reingold`, `lgl`, `reingold_tilford`, `reingold_tilford_circular`, and `sugiyama`.  

Another popular package for network analysis is `sna` by @sna. This package was designed specifically for social network analysis (sna), so it also contains much more capabilities for network analysis in addition to visualization. Like `igraph`, `sna` contains both 2D and 3D layout methods. The 2D layout algorithms available in `sna` are `circle`, `circrand`, `eigen`, `fruchtermanreingold`, `geodist`, `hall`, `kamadakawai`, , `mds`, `princoord`, `random`, `rmds`, `segeo`, `seham`, `spring`, `springrepulse`, and `target`. 

Research into possible layout algorithms is important, but it ignores some of the things that statisticians usually consider when visualizing data. For instance, since the location of points in 2D space contains no information about the data, how else should this information be visualized? As an example, consider a friendship network of students at a university. Representing this network as simple points and lines leaves a lot of information out. Some information that could be incorporated includes the students’ majors, year in school, and whether the students have ties through their classes or their extracurricular activities. In the network visualization, this information can be mapped to color of point, shape of point, and linetype, respectively. Adding this aesthetic information helps to make up for the loss of two dimensions of visual perception and to bring the network visualization into the world of statistical graphics.   

### The Importance of `ggplot2` {#iloveggplot2}

The `gg` of `ggplot2` is for the "grammar of graphics". The grammar of graphics is a well-defined theory for creating statistical graphics described in @wilkinson:1999 and @ggplot2. In the grammar, a plot has layers, each of which has four distinct pieces: the data and aesthetic mapping, a statistical transformation, a geometric object, and a position adjustment. The aesthetic mapping takes the data and *maps* the variables in the data frame to visual features. Some of these features are horizontal and vertical placement in the plane, size of the geometric object and color of the geometric object. The statistical transformation dictates how to transform the data to the values that create the visual feature. Some `stats` are `identity` (no change in data), `bin`, and `smooth`. The geometric object or `geom` is the tool used to draw a plot layer. Some `geoms` are `point`, `line` and `bar`. Finally, the position adjustment is there to slightly change the position of the visual features in order to better view the data. This is typically only a probelm with discrete data, where overplotting can occur. Some position adjustments are `identity`, `jitter`, and `dodge`. 

With the theory well defined and constructed, the `ggplot2` package allows for creation of rich, visually dense plots. The user can combine multiple aesthetic mappings to view four variables at once or view many data sets of similar scale at once. The widespread use of `ggplot2` and the many packages that have built upon `ggplot2` to create visualizations above and beyond what it is capable of by itself make the `ggplot2` package an ideal framework on which to build additional methods of network visualization in R.

First, the data structure required in `ggplot2` is fairly simple: data frames. Some other network packages contain network data structures unique to them, like the `igraph` class of data in the `igraph` packages or the `network` class of data in the `network` package. These unique structures come with unqiue syntax that can make customizing visualizations tricky. Additionally, the default visualizations in these packages are not very pleasing to the eye, as is shown with the random graph examples from `igraph` and `network` in Figure \@ref(fig:graphvizex). 
```{r graphvizex, out.width="50%", fig.cap="The same random network plotted with the default options in \texttt{igraph} (at left) and \texttt{network} (at right.", fig.show='hold'}
set.seed(123456)
m <- matrix(rbinom(25,1,.4),5,5)
migraph <- igraph::graph_from_adjacency_matrix(m, mode = "directed")
mnetwork <- network::as.network(m, loops = TRUE)
plot(migraph)
plot(mnetwork)
```

As I will discuss in \@ref(ch3), network visualization within the `ggplot2` framework results in beautiful, easily customizable plots. 

## Summary

Stochastic actor-oriented models are a rich and interesting set of models because of the complicated nature of statistical network modeling and the variety in choice of parameters available to the researcher. In the next three chapters, my aim is to fully characterize the structure and function of these models. I will do this using the lineup protocol for visual inference, and the R package, `geomnet` that I created as a part of this work.