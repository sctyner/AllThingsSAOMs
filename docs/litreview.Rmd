# Literature Review {#litreview}

## Seeing the Forest Before Looking at Trees {#intro}

Social networks have been studied for decades, beginning with a few foundational works, the most well known of which is the 1967 study, "The Small World Problem" by Stanley Milgram (@goldenberg09). But in recent years, the study of social networks has grown wildly in popularity due to an increase in the availability of and easy of access to social network data. The digital revolution has led to the creation of social media, linking people from all over the world in a way we never have been before. Now that platforms like Facebook, Twitter, and LinkedIn permeate our world, just about everyone knows what social networks are. In academic circles, collaboration networks are a type of social network that have been extensively studied and can even be a point of pride, like a mathematician's Erd&#x00F6;s  number (@erdos). Social networks are a rich source of knowledge, but the data format does not fit easily within traditional data collection paradigms. Traditionally, data collection involves a set of units of the same, or at least similar, kind, on which observations are made. The storage of traditional data is simple and organized: rows contain variable values collected from units. These units can be people, plants, animals, stocks, objects, fields, and anything else under the sun, but one social network consits of many units, yet on the whole is just one observation. When observing a social network, one observes the possibly very numerous actors (also referred to as vertices or nodes) and the relationships (also referred to as edges or ties) between those actors. One can also collect information on the nodes and the edges separately, such as the age or gender of people and the length of their relationship or how strong it is in a friendship network. Thus, information on the entire network is more difficult to store than traditional data with which statisticians usually work. 

This apparent difficulty has not stopped researchers in many different fields from studying social and other types of networks. Sociologists work with human relationship networks of all kinds imaginable, biologists work with protein-protein interaction networks, neurologists use fMRI scans to study biologic neural networks, and the list goes on. These disciplines worked separately for many years, each developing their own measures, softwares, and theories about the fundamental properties of networks. And although statisticians were comparatively late to the party, many statistical models exist for network analysis. Beginning with the classic Erd&#x00F6;s-R&#x00E9;nyi random graph model and varying in structure, complexity, and application to include longitudinal network data, such as continuous time markov chain models (@goldenberg09). The many varying models that exist just for social network analysis are impressive, but I focus my research on one type of continuous time markov chain (CTMC) models, called Stochastic Actor-Oriented Models (SAOMs). A full introduction to the various models that exist for social network analysis is presented in Section \@ref(models), and a full introduction to the structure and theory of SAOMs is presented in Section \@ref(saoms). 

## Statistical Models for Social Networks {#models}

The literature on statistical models for networks is extensive. In their thorough "Survey of Statistical Models", Goldenberg et al separate these models in to two primary classes: static and dynamic. I discuss the several types of models in each of these two categories after a brief introductory section on general network terminology and notation. 

### Basic Network Terminology and Notation {#netterm}

Formally, a network is a collection of nodes and the set of ties between them. Nodes are also referred to as vertices primarily in the graph theory literature or actors in the sociology literature, while ties are also called edges or relationships. In graph theory, a network is defined with respect to its nodes and edges, and a network $G$ is equivalently written as $G(\mathcal{N}, \mathcal{E})$, where $\mathcal{N}$ is the collection of nodes, or nodeset, and $\mathcal{E}$ is the collection of edges, or edgeset. Typically, the nodes are numbered so that $\mathcal{N} = {1, 2, \dots, n}$, where $n$ is the total number of nodes in the network. The edgeset $\mathcal{E}$ is usually described as a set of pairs, written as $(i,j)$ or $i \mapsto j$ or simply $ij$, where $i \neq j \in \mathcal{N}$. In an undirected network, the ordering of $i$ and $j$ does not matter: there is no parent-child relationship, to use a term from graph theory, just a connection of some kind. In a directed graph, however, the order does matter: the tie $(i,j)$ is not equivalent to the tie $(j,i)$. In an undirected graph, the number of possible edges is $\binom{n}{2}$, while in directed graphs it is $n(n-1)$, assuming no self-loops (also called self-ties or simply loops) and only allowing for at most one edge between any two nodes. 

In statistical network analysis, a network is denoted by $x$ if it is observed or by $X$ if it is being treated as unobserved or as a random variable. Following this convention, edges in the networks $x$ or $X$ are denoted by $x_{ij}$ or $X_{ij}$, respectively. If the edge $i \mapsto j$ is present, $x_{ij} = 1$, whereas $x_{ij} = 0$ if the edge is not present. If $x$ is undirected, then $x_{ij} = x_{ji} \forall i \neq j \in \mathcal{N}$. If $x$ is directed, then $x_{ij}$ may equal $x_{ji}$, but this is not required and should not be assumed. Note that the definition of binary edge variables makes the assumption that edges are unweighted and that their cannot be more than one edge between two nodes. There are graphs and networks with weighted edges or with multiple ties between nodes, such as correlation networks used for modelling fMRI data or network-based epidemic modeling with finite, discrete state spaces (@Kolaczyk2009). The models I discuss here, including the stochastic actor-oriented models that are my primary focus, are all for unweighted networks, though some allow for extension to weighted networks. 

A network $x$ can also be expressed as an $n \times n$ matrix of 0s and 1s called the adjacency matrix, denoted $\mathcal{A}(x)$. The $ij^{th}$ entry of this matrix, $a_{ij}$ is 1 if there is an edge between nodes $i$ and $j$ and 0 otherwise. Typically, in statstical network analysis, the diagonal entries of this matrix, $a_{ii}$ are structurally 0, as self-ties or self-loops are not allowed or do not make sense. 

### Static Network Models {#staticnets}

The Erd&#x00F6;s-R&#x00E9;nyi random graph model is widely regarded as the first random graph model (@goldenberg09). In this model, first introduced in 1959 in  @er59, a random, undirected graph or network, $G$, is described in terms of its nodeset, $N$, and its edgeset, $E$, where $E$ is a random subset of the $\binom{|N|}{2}$ possible edges in the nodeset. The parameter in this model is $p$, the probability of an edge between any two nodes in $N$. The likelihood is written in terms of $|E|$ and $p$, 
$$f_G(|E| | p, N) = p^{|E|}(1-p)^{\binom{|N|}{2} - |E|}.$$
The properties and asymptotic behavior of this network model are well-established (@goldenberg09). Nodes in networks generated using this model will all have about the same degree, or number of incident edges, which is a very unrealistic property for networks to have. As such, many other models have been devised over the years as a way to better capture the the network creation process underlying real-world networks. 

A set of models which has also been very extensively studied is the exponential random graph family of models (ERGMs). The first, less general form of these models is the $p_1$ model for social networks, first introduced in @p1model. The $p_1$ model was developed for modelling directed networks, also called directed graphs or digraphs. In this model, the edges state, $(x_{ij}, x_{ji})$ between a pair of nodes, $(i, j)$ for all $i \neq j \in N$, could exist in one of four possible states: $(0,0)$ (no ties between $i,j$), $(1,0)$ (a tie from $i$ to $j$), $(0,1)$ (a tie from $j$ to $i$), or $(1,1)$ (a tie from $i$ to $j$ and from $j$ to $i$). Each one of these states has some probability such that the four state probabilities sum to 1 for each pair $(i,j)$. These probabilities are described in terms of five kinds of parameters: $\theta$, a base rate for edge creation; $\alpha_i$, an effect for an outgoing edge with parent node $i$; $\beta_j$, an effect for an incoming edge with child node $j$; $\rho_{ij}$, an effect of  reciprocated ties; and $\lambda_{ij}$, a normalizing constant to ensure that the four possible edge states of have probabilities summing to 1. Below, let $x_{ij} = 1$ when the edge from $i$ to $j$ exists and $x_{ij} = 0$ otherwise, and let $x_{ji} = 1$ when the edge from $j$ to $i$ exists and $x_{ji} = 0$ otherwise. Then, the edge state, $(x_{ij},x_{ji})$ between nodes $i$ andd $j$ is modeled as:
$$\log f_X((x_{ij},x_{ji})| \lambda_{ij}, \alpha_i, \alpha_j, \beta_i, \beta_j, 
\theta, \rho_{ij}) = \lambda_{ij} + x_{ij}(\alpha_i + \beta_j + \theta) + x_{ji}(\alpha_j + \beta_i + \theta) + x_{ij}x_{ji}\rho_{ij} $$
If each reciprocation parameter, $\rho_{ij}$, were unique to each edge, there would be a lack of identifiability in the model, which can be remedied by (i) not having a reciprocation effect ($\rho_{ij} = 0$ for all $i \neq j$), (ii) having a constant effect for reciprocation ($\rho_{ij} = \rho$ for all $i \neq j$), or (iii) having edge-dependent reciprocation ($\rho_{ij} = \rho + \rho_i + \rho_j$). Assuming scenario (ii), the log-likelihood function for a network $X$ can be written in exponential family form:
$$\log f_X(x | \boldsymbol{\lambda}, \boldsymbol{\alpha}, \boldsymbol{\beta}, \rho, \theta) \propto \theta \sum_{i,j} x_{ij} + \sum_i x_{i+}\alpha_i + \sum_j x_{+j}\beta_j + \rho\sum_{i,j}x_{ij}x_{ji},$$
where the minimally sufficient statistics are $x_{i+}$, the outdegree of each node $i$, $\sum_j x_{+j}$, the indegree of each node $j$, and $\sum_{i,j}x_{ij}x_{ji}$, the number of reciprocal ties in the network. This $p_1$ set of models is problematic because, as "the number of {$\alpha_i$} amd {$\beta_j$} increase directly with the number of nodes, [so] we have no consistency results for the maximum likelihood estimation" (@goldenberg09, p. 28). An extension of the $p_1$ model is the $p_2$ model, introduced by @p2model. This model is essentially a mixed-effects model version of the $p_1$ model, with node-level fixed effects for the outgoing edge effects $\boldsymbol{\alpha}$ and the incoming edge effects $\boldsymbol{\beta}$, and edge-level fixed effects for the edge rate effects $\boldsymbol{\theta}$ and reciprocity rates $\boldsymbol{\rho}$. The random effects, added to the covariate effects for $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$, have normal distribution with mean zero and variance parameters $\sigma^2_{\alpha}$ and $\sigma^2_{\beta}$. 

The final form for ERGMs is far more general than the $p_1$ and $p_2$, and is for undirected, rather than directed, networks. There are many more possible sufficient statistics other than the outdegree, indegree, and reciprocal ties. Other graph structures that are considered are the number of triangles, $T(X) = \sum_{i \neq j \neq h} x_{ij}x_{ih}x_{jh}$, and the number of $k$-stars, $S_k(X) = \sum_i \binom{x_{i+}}{k}$, where $k = 2$ is most commonly chosen. The form of the likelihood for $X$ following this general type of ERGM is 
$$f(X|\boldsymbol{\theta}, \tau) = \exp\left(\sum_k \theta_k S_k(X) + \tau T(X) + \psi(\theta, \tau)\right),$$ 
where $\theta_k$ and $\tau$ are parameters and $\psi(\theta, \tau)$ is the normalizing constant.  A problem with this model arises when one considers the nested nature of the sufficient statistics. For example, an edge can be contained in a 2-star, which can be contained in a triangle. So, the sufficent statistics can be dependent. Despite this flaw, this type of ERGM has been studied extensively, and many methods for parameter estimation exist, for example in the \texttt{R} packages \texttt{statnet} and \texttt{sna} (, @Rsoft,@statnet, and @sna). 

Another set of models includes extensions of the Erd&#x00F6;s-R&#x00E9;nyi (ER) random graph model. A natural way to extend the ER model is to vary the expected node degree of the graph. These models include the preferential attachment model or power-law degree distribution models. XXX TALKE MORE ABOUT POWER-LAW NETWORKS XXX . Another model type, the exchangeable random graph model of @exchange, adds weak dependence into the edge sampling procedure.

XXX TALK ABOUT THE OTHER COUPLE OF STATIC ONES

### Dynamic Network Models {#dynamicnets}

Dynamic network models are a very important part of statistical network analysis because discovering how networks form and change over time can help us make predictions.XXX THAT IS A DUMB SENTENCE FIX IT LATER XXXX Like with static models, the literature on dynamic network models begins with a fairly simple random graph model. XXX ADD THE EXAMPLES XXX

## Stochastic Actor-Oriented Models for Longitudinal Social Networks. {#saoms}

The phrase Stochastic Actor-Oriented Model is quite a mouthful, but it contains most of the important information about the model. First, the model is changing in time in order to accomodate for observations from the same network made at different points in time. Second, it allows for changes in network structure due to actor-level covariates. These two properties are crucial to understanding networks as they exist naturally. Most social networks are ever-changing as relationships decay or grow, and most actors (or nodes) in social networks have inherent properties that could affect how they change their place within the network. 

### Terminology, Notation, and Mathematical Definition of SAOMs {#saomsnote}

A longitudinal network is a network consisting of the same set of $n$ nodes that is changing over time, and is observed at $M$ discrete time points, $t_1, \dots, t_M$. Denote these network observations $x(t_1), \dots, x(t_M)$. The SAOM assumes that this longitudinal network is embedded within a continuous time markov process (CTMP), call it $X(T)$. This process is almost entirely unobserved. The process $X(T)$ theoretically exists outside of the range of observation, but for simplicity of notation, assume that the beginning of the process, $X(0)$ is equivalent to the first observation $x(t_1)$, while the end of the process $X(\infty)$ is equivalent to the last observation $x(t_M)$.  The observations $x(t_1), \dots, x(t_M)$ are observed states of the process, $x(t_1) \equiv X(0), x(t_2) \equiv X(T_{t_2}), \dots, x(t_{M-1}) \equiv X(T_{t_{M-1}}), x(t_M) \equiv X(\infty)$, but the time points $t_m$ and $T_{t_m}$ for $m = 2, \dots M-1$ are not equivalent. The process $X(T)$ is a series of single tie changes, in which one actor at a time is given the opportunity to add or remove one outgoing tie.  These opportunities for change can arise at a different rate for each actor, and the overall rate of change, the distribution of the waiting times that *any* actor will be given the opportunity to change is a function of all actors' rates. Additionally, once an actor is given the chance to change a tie, it tries to maximize a sort of utility function based on the current and potential future states of the network. These functions are described in detail in subsections \@ref(saomrate) and \@ref(saomobjective). 

### The Rate Function {#saomrate}

In the network $x$ and for each actor $i$ in this network, the rate function is most generally denoted $\lambda_i(\alpha, \rho, x, m)$, which dictates how quickly actor $i$ gets opportunities to change one of its ties, $x_{ij}$ in the time period $t_{m} \leq T < t_{m+1}$. In this function, $\alpha$ and $\rho$ are parameters, $x$ is the current network state at time $m$. Note that $x \in \mathcal{X}$, where $\mathcal{X}$ is the space of possible networks given the $n$ nodes in the network, and that $|\mathcal{X}| = 2^{n(n-1)}$. We assume that the actors $i$ are conditionally independent given their current ties, $x_{i1}, \dots, x_{in}$. This assumption gives the rate function for the whole network as $\lambda(\alpha, \rho, x, m) = \sum_i \lambda_i(\alpha, \rho, x, m)$. For any time point, $T$, where $t_m \leq T < t_{m+1}$, the waiting time to the next change opportunity by actor $i$ has distribution *Exponential*$(\lambda_i\alpha, \rho, x, m))$ in order to achieve the memorylessness property of a Markov process. Thus, the waiting time to the next change opportunity by *any* actor in the network has distribution *Exponential*($\sum_i \lambda_i\alpha, \rho, x, m)$). There are many possibilities for the rate function, $\lambda_i$. The simplest is that it is constant over all actors and all unobserved timepoints between observations $x(t_{m-1})$ and $x(t_m)$, $\lambda_i(\alpha, \rho, x, m)) = \alpha_m$. The rate function can also depend on covariate values, call them $\mathbf{z}_{i}(t_m)$, of the actors or structural network elements such as outdegree, or both. For instance, assume $\lambda_i(\alpha, \rho, x, m)) = \lambda_{i1}\lambda_{i2}\lambda_{i3}$, where $\lambda_{i1}$ is constant over $m$, $\lambda_{i2}$ depends on the actor covariates, and $\lambda_{i3}$ depends on a structural network property for node $i$. $\lambda_{i2}$ might be written as $\lambda_{i2} = \exp\left(\sum_h \rho_h z_{ih}(t_m)\right)$, where there are $h = 1, \dots, H$ actor covariates of interest, each with their own parameter $\rho_h$. $\lambda_{i3}$ can be written as a function of the outdegree of node $i$, denoted $x_{i+}$ with its own parameter $\alpha_{H+1}$, so that, for example, $\lambda_{i3} = \frac{x_{i+}}{n-1}\exp(\alpha_{H+1}) + \left(1-\frac{x_{i+}}{n-1}\right)\exp(-\alpha_{H+1})$. When $H=0$, this form of $\lambda_{i3}$ is equivalent to the model proposed by @wassermanrecip, which is one of the first models proposed for modeling dynamic networks as continuous-time Markov processes (@snijders01).  Given that a change occurs, the probability that actor $i$ is given the power to change a tie is $$\frac{\lambda_i(\alpha, \rho, x, m))}{\sum_i \lambda_i(\alpha, \rho, x, m))}$$.
 
### The Objective Function {#saomobjective} 

Thanks to the conditional dependence assumptions in the model, we can consider the objective function for each node separately, since only one tie from one node is changing at a time. The objective function is written as $f_i(\boldsymbol{\beta}, x), x \in \mathcal{X}$. The vector $\boldsymbol{\beta}$ are the parameters of the model and $x$ is any possible state of the network. Given the focal or ego node, $i$, there are $n$ possible steps for the actor $i$ to take: either one of all current ties $x_{ij}$ will be destroyed, a new tie will be created, or no change will occur. 

The parameters, $\beta$, are attached to various actor-level network statistics. There are always at least two parameters, $\beta_1$ for the outdegree of a node, and $\beta_2$ for the number of reciprocal ties held by a node. There are many possible parameters $\beta$ to add to the model. They can be split up into two groups: first, the structural effects, which only depend on the structure of the network. The inclusion of these effects has origin in the ERGMs discussed previously for static networks. The second set of effects are the actor-level or covariate effects. These effects 